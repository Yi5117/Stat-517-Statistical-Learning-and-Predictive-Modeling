---
title: "Walmart Project"
author: "Yuha Yi"
date: "December 11, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("C:\\Users\\yiyuh\\Documents\\College\\Fall 2018\\Stat 517 - Machine Learning\\Final Project - Stats 517\\Walmart proj")
#install.packages("reshape")
source('data_prep.R')
source('forecast.R')
source('clustering.R')
train <- read.csv("train.csv")
test <- read.csv("test.csv")
store.matrix <- reshape.by.stores(train)

```

```{r}

#Perform and plot hierarchical clustering based on dissimilarity computation of weekly sales vs stores
tsdist<-calculate.ts.dist(store.matrix)
hc<-hclust(tsdist)
plot(hc)

#Upon visual inspection of the cluster plot, I decide to cluster the data into 4 clusters
rect.hclust(hc,k=4)
clust.vec <- cutree(hc,k=4)
clust.vec[hc$order]
#temp remove date column from store matrix
store.matrix.wodate <- store.matrix[,-1]
```

```{r}

##Creating clusters
cluster1 <- store.matrix.wodate[,clust.vec==1]
cluster2 <- store.matrix.wodate[,clust.vec==2]
cluster3 <- store.matrix.wodate[,clust.vec==3]
cluster4 <- store.matrix.wodate[,clust.vec==4]

##Force clusters in a ts() object
cluster1.ts <-ts(rowMeans(cluster1),frequency=52)
cluster2.ts <-ts(rowMeans(cluster2),frequency=52)
cluster3.ts <-ts(rowMeans(cluster3),frequency=52)
cluster4.ts <-ts(rowMeans(cluster4),frequency=52)
```

```{r}
### Time Series Forecasting
library(tseries)
#Test for stationarity by performing ADF test
adf.test(cluster1.ts, alternative='stationary') #Dickey-Fuller = -5.279, Lag order = 5, p-value = 0.01
adf.test(cluster2.ts, alternative='stationary') #Dickey-Fuller = -5.2943, Lag order = 5, p-value = 0.01
adf.test(cluster3.ts, alternative='stationary') #Dickey-Fuller = -5.3377, Lag order = 5, p-value = 0.01
adf.test(cluster4.ts, alternative='stationary') #Dickey-Fuller = -5.1801, Lag order = 5, p-value = 0.01

#To get an estimate coefficients for AR and MA, plot the ACF and PACF curve for each cluster
#The PACF and ACF lag orders which cross the confidence boundaries, are candidates for AR and MA coefficients respectively
tsdisplay(cluster1.ts)
```

```{r}
tsdisplay(cluster2.ts)
```

```{r}
tsdisplay(cluster3.ts)
```

```{r}
tsdisplay(cluster4.ts)

```

```{r}

#It is observed that all 4 clusters have a clear seasonal pattern for period length of 52 weeks.
#Hence, the seasonal order for ARIMA modeling will be defaulted to 'seasonal= list(order = c(0,1,0), period = 52'
#To find the optimal pdq coeffecients for the trend component, run the following function for each cluster


#manually try out combinations of p,d,q
cluster1.fit<-Arima(cluster1.ts,order=c(1,0,1), seasonal = list(order = c(0,1,0), period = 52), include.mean = FALSE)#AIC=2174.26   AICc=2174.54   BIC=2181.79
cluster2.fit<-Arima(cluster2.ts,order=c(1,0,2), seasonal = list(order = c(0,1,0), period = 52), include.mean = FALSE)#AIC=2221.03   AICc=2221.49   BIC=2231.07
cluster3.fit<-Arima(cluster3.ts,order=c(1,0,1), seasonal = list(order = c(0,1,0), period = 52), include.mean = FALSE)#AIC=2225.74   AICc=2226.02   BIC=2233.28
cluster4.fit<-Arima(cluster4.ts,order=c(1,0,1), seasonal = list(order = c(0,1,0), period = 52), include.mean = FALSE)#AIC=2207.87   AICc=2208.15   BIC=2215.41

```

```{r}
### Evaluating forecast accuracy
#
#
# Visually check the fit of the arima model by plotting the ACF, PACF graph of the residuals
# Residuals which fall within the confidence boundaries suggest a good fit
tsdisplay(residuals(cluster1.fit))

```

```{r}
tsdisplay(residuals(cluster2.fit))
```

```{r}
tsdisplay(residuals(cluster3.fit))
```

```{r}
tsdisplay(residuals(cluster4.fit))
```

```{r}
#The mean absolute percentage error turns out to be
#5.837927 for cluster 1
#5.824512 for cluster 2
#5.570019 for cluster 3 and
#6.833386 for cluster 4
```
